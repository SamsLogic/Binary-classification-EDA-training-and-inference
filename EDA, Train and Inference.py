# -*- coding: utf-8 -*-
"""Arya AI Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Crag3hX87HamRBvw12mgGKG-nyXv1nvK

# Import Libraries and Data
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import seaborn as sns

from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

filepath = ''
train_data = pd.read_csv(os.path.join(filepath,'train.csv'))
test_data = pd.read_csv(os.path.join(filepath,'test_set.csv'))

train_data.head()

test_data.head()

"""# Data Cleaning"""

print(train_data.Y.value_counts())

class_weights = len(train_data[train_data.Y == 0])/len(train_data[train_data.Y == 1])
print(class_weights)

"""## Check for Null Values"""

if train_data.isna().sum().all() == 0:
    print('No Null values')
else:
  print('There are Null values')

if test_data.isna().sum().all() == 0:
    print('No Null values')
else:
  print('There are Null values')

"""## Check for outliers"""

print(train_data.max(axis=0).values)

print(train_data.min(axis=0).values)

for i in range(1,len(train_data.columns[1:-1]),10):
    train_data[train_data > 0][train_data.columns[i:i+9]].plot(kind='box', title='boxplot', showmeans=True)

for col in train_data.columns[1:-1]:
    train_data[train_data[col] == train_data[col].min()]["Y"].value_counts().plot(kind='bar')
    plt.title(col)
    plt.show()

# train_data.drop(index=train_data[train_data['X57'] == train_data['X57'].min()].index, inplace=True)

for col in train_data.columns[1:-1]:
    q3 = 3*(len(train_data[train_data[col] > 0][col])+1)//4
    val = train_data[train_data[col] > 0][col].sort_values().iloc[q3]
    train_data.loc[train_data[col] > val, col] = val
    test_data.loc[test_data[col] > val, col] = val

for i in range(1,len(train_data.columns[1:-1]),10):
    train_data[train_data > 0][train_data.columns[i:i+9]].plot(kind='box', title='boxplot', showmeans=True)

"""# Correlation of variables with the target"""

sns.heatmap(train_data[train_data.columns[1:-1]].corr())

sns.barplot(x=train_data.columns[1:-1],y=train_data[train_data.columns[1:-1]].corrwith(train_data['Y']))

"""Since columns - X12, X14, X23, X38, X40, X54 are highly correlated and less correlated with the target we can ignore these columns."""

train_data.drop(columns=['X12', 'X14', 'X23', 'X38', 'X40', 'X54'],inplace=True)
test_data.drop(columns=['X12', 'X14', 'X23', 'X38', 'X40', 'X54'],inplace=True)

"""# Dimensionality reduction"""

ss = StandardScaler()
train_data[train_data.columns[1:-1]] = ss.fit_transform(train_data[train_data.columns[1:-1]])
test_data[test_data.columns[1:]] = ss.fit_transform(test_data[test_data.columns[1:]])

components = 8
pca = PCA(n_components = components)
x_train = pca.fit_transform(train_data[train_data.columns[1:-1]])
y_train = train_data['Y'].values
x_test = pca.transform(test_data[test_data.columns[1:]])

for j in range(components):
    fig, ax = plt.subplots(2,components//2)
    for i in range(components):
        if i <= components//2-1:
            ax[0,i].scatter(x_train[y_train==0][:,j],x_train[y_train==0][:,i])
            ax[0,i].scatter(x_train[y_train==1][:,j],x_train[y_train==1][:,i])
        else:
            ax[1,i-components//2].scatter(x_train[y_train==0][:,j],x_train[y_train==0][:,i])
            ax[1,i-components//2].scatter(x_train[y_train==1][:,j],x_train[y_train==1][:,i])
    fig.suptitle(f'PC {j}')
    plt.show()

"""# Data Split"""

X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.25,random_state=42)

print(X_train.shape,Y_train.shape,X_val.shape,Y_val.shape)

"""# Training"""

lr = LogisticRegressionCV(cv=5,random_state=45,class_weight='balanced')
lr.fit(X_train,Y_train)
pred_lr = lr.predict(X_val)

svc = SVC(class_weight='balanced',random_state=45)
svc.fit(X_train,Y_train)
pred_svc = svc.predict(X_val)

rfc = RandomForestClassifier(class_weight='balanced',random_state=45)
rfc.fit(X_train,Y_train)
pred_rfc = rfc.predict(X_val)

xgb = XGBClassifier(class_weight='balanced',n_estimators=1000,verbosity=0,random_state=45)
xgb.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],eval_metric='auc',early_stopping_rounds=200,verbose=0)
pred_xgb = xgb.predict(X_val)

lgb = LGBMClassifier(class_weight='balanced',random_state=45)
lgb.fit(X_train,Y_train)
pred_lgb = lgb.predict(X_val)

"""# Validation

## AUC Score of Multi Models over Validation sets
"""

print('Logistic Regression', roc_auc_score(Y_val, pred_lr))
print('Support vecotr classifier', roc_auc_score(Y_val, pred_svc))
print('Random Forest Classifier', roc_auc_score(Y_val, pred_rfc))
print('XGBoost', roc_auc_score(Y_val, pred_xgb))
print('LightGBM', roc_auc_score(Y_val, pred_lgb))

"""## F1 Score of Multi Models over Validation sets"""

print('Logistic Regression', f1_score(Y_val, pred_lr))
print('Support vecotr classifier', f1_score(Y_val, pred_svc))
print('Random Forest Classifier', f1_score(Y_val, pred_rfc))
print('XGBoost', f1_score(Y_val, pred_xgb))
print('LightGBM', f1_score(Y_val, pred_lgb))

"""## Confusion Matrix over prediction from Validation sets"""

print('Logistic Regression\n', confusion_matrix(Y_val, pred_lr))
print('Support vecotr classifier\n', confusion_matrix(Y_val, pred_svc))
print('Random Forest Classifier\n', confusion_matrix(Y_val, pred_rfc))
print('XGBoost\n', confusion_matrix(Y_val, pred_xgb))
print('LightGBM\n', confusion_matrix(Y_val, pred_lgb))

print('Logistic Regression\n', classification_report(Y_val, pred_lr))
print('Support vecotr classifier\n', classification_report(Y_val, pred_svc))
print('Random Forest Classifier\n', classification_report(Y_val, pred_rfc))
print('XGBoost\n', classification_report(Y_val, pred_xgb))
print('LightGBM\n', classification_report(Y_val, pred_lgb))

"""# Inference"""

pred = xgb.predict(x_test)
submission = test_data.copy()
submission.drop(columns=submission.columns[1:],inplace=True)
submission['Y'] = pred

submission.to_csv('Submission.csv',index=False)

submission